{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNNExplainer Tutorial\n",
    "\n",
    "This tutorial demonstrates how to use `GNNExplainer` from the Captum library to explain predictions made by a Graph Neural Network (GNN). GNNExplainer identifies a compact subgraph structure and a small subset of node features that are most influential for a GNN's prediction.\n",
    "\n",
    "**Reference:** [GNNExplainer: Generating Explanations for Graph Neural Networks](https://arxiv.org/abs/1903.03894)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, let's install and import the necessary libraries. We'll need `torch`, `torch_geometric` for graph data and GNN layers, `captum` for GNNExplainer, and `networkx` / `matplotlib` for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q torch_geometric\n",
    "!pip install -q captum\n",
    "!pip install -q networkx matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import KarateClub\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming GNNExplainer is in this path relative to the notebook or installed in the env\n",
    "# For a real Captum integration, it would be: from captum.attr import GNNExplainer\n",
    "from captum.attr._gnn.gnn_explainer import GNNExplainer # Adjust if necessary\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "We'll use the classic Zachary's Karate Club dataset from `torch_geometric.datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = KarateClub()\n",
    "data = dataset[0].to(device)\n",
    "print(f\"Dataset: {dataset.name}\")\n",
    "print(f\"Number of nodes: {data.num_nodes}\")\n",
    "print(f\"Number of edges: {data.num_edges}\")\n",
    "print(f\"Number of features: {data.num_node_features}\")\n",
    "print(f\"Number of classes: {dataset.num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Definition\n",
    "\n",
    "Let's define a simple Graph Convolutional Network (GCN) model for node classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        x = self.conv1(x, edge_index, edge_weight=edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_weight=edge_weight) # Pass edge_weight to second layer too if desired\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = GCN(dataset.num_node_features, 16, dataset.num_classes).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "We need to train the model to get meaningful explanations. GNNExplainer works by finding important graph structures for the *current* model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "model.eval()\n",
    "_, pred_labels = model(data.x, data.edge_index).max(dim=1)\n",
    "correct_nodes = (pred_labels[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "accuracy = int(correct_nodes) / int(data.test_mask.sum())\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Attribution with GNNExplainer\n",
    "\n",
    "Now, let's use GNNExplainer to understand the prediction for a specific node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GNNExplainer\n",
    "explainer = GNNExplainer(model)\n",
    "\n",
    "# Choose a target node to explain\n",
    "target_node_idx = 0 \n",
    "print(f\"Explaining node: {target_node_idx}\")\n",
    "print(f\"Node true label: {data.y[target_node_idx].item()}\")\n",
    "print(f\"Node predicted label: {pred_labels[target_node_idx].item()}\")\n",
    "\n",
    "# Get attributions\n",
    "# GNNExplainer's attribute method might require target_class if not taking argmax internally\n",
    "# For node classification, we usually explain the predicted class or the true class.\n",
    "target_class = pred_labels[target_node_idx].item()\n",
    "\n",
    "node_feat_mask, edge_mask = explainer.attribute(\n",
    "    inputs=data.x, \n",
    "    edge_index=data.edge_index, \n",
    "    target_node=target_node_idx,\n",
    "    target_class=target_class, # Specify class if GNNExplainer needs it\n",
    "    num_epochs=150, # Number of epochs to train the masks\n",
    "    lr=0.01 # Learning rate for mask optimization\n",
    ")\n",
    "\n",
    "print(\"\\nNode Feature Mask (first 5 features):\")\n",
    "print(node_feat_mask[:5])\n",
    "print(\"\\nEdge Mask (first 5 edges):\")\n",
    "print(edge_mask[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `node_feat_mask` tells us the importance of each input feature for the specified node's prediction. The `edge_mask` indicates the importance of each edge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization\n",
    "\n",
    "Let's visualize the explanation. We can highlight the important edges based on the `edge_mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph_with_masks(edge_index, edge_mask, target_node_idx, title, node_labels=None, threshold=0.5):\n",
    "    num_nodes = edge_index.max().item() + 1\n",
    "    g_nx = nx.Graph()\n",
    "    g_nx.add_nodes_from(range(num_nodes))\n",
    "    \n",
    "    # Add edges with weights from edge_mask\n",
    "    for i, (u, v) in enumerate(edge_index.t().tolist()):\n",
    "        g_nx.add_edge(u, v, weight=edge_mask[i].item())\n",
    "        \n",
    "    pos = nx.spring_layout(g_nx, seed=42) # Kamada-Kawai for better structure sometimes\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Draw nodes\n",
    "    node_colors = ['lightblue'] * num_nodes\n",
    "    node_colors[target_node_idx] = 'red' # Highlight target node\n",
    "    nx.draw_networkx_nodes(g_nx, pos, node_color=node_colors, node_size=500)\n",
    "    \n",
    "    # Draw edges: highlight important ones\n",
    "    edge_weights = [g_nx[u][v]['weight'] for u, v in g_nx.edges()]\n",
    "    edge_alphas = [w if w > threshold else 0.1 for w in edge_weights] # Make less important edges more transparent\n",
    "    edge_widths = [3*w if w > threshold else 0.5 for w in edge_weights]\n",
    "\n",
    "    nx.draw_networkx_edges(g_nx, pos, width=edge_widths, alpha=edge_alphas, edge_color='gray')\n",
    "    \n",
    "    # Draw labels\n",
    "    if node_labels is not None:\n",
    "        labels = {i: f\"{i}\\n(L:{node_labels[i].item()})\" for i in g_nx.nodes()}\n",
    "    else:\n",
    "        labels = {i: str(i) for i in g_nx.nodes()}\n",
    "    nx.draw_networkx_labels(g_nx, pos, labels=labels, font_size=10)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the explanation\n",
    "plot_graph_with_masks(data.edge_index, edge_mask, target_node_idx, \n",
    "                        f'GNNExplainer Explanation for Node {target_node_idx} (Predicted: {pred_labels[target_node_idx].item()})',\n",
    "                        node_labels=data.y, threshold=0.2) # Lower threshold for more visibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot above, the target node is highlighted (e.g., in red). Edges with higher importance scores from the `edge_mask` are shown as thicker and less transparent. This helps identify the computational subgraph that GNNExplainer deems important for the prediction of the target node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Feature Importance\n",
    "The `node_feat_mask` indicates which input features are important. For the Karate Club dataset, features are one-hot encoded node identities, so the feature mask might not be as directly interpretable as in other contexts. However, if features had semantic meaning (e.g., age, degree in a social network), this mask would highlight which of those contributed most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Node Feature Mask for Node {target_node_idx}:\")\n",
    "for i, val in enumerate(node_feat_mask):\n",
    "    if val > 0.1: # Show features with some importance\n",
    "        print(f\"  Feature {i}: {val.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "This tutorial demonstrated the basic workflow of using `GNNExplainer` with Captum:\n",
    "1. Training a GNN model.\n",
    "2. Instantiating `GNNExplainer` with the trained model.\n",
    "3. Calling the `attribute` method to get node feature and edge masks.\n",
    "4. Visualizing these masks to interpret the model's prediction for a specific node.\n",
    "\n",
    "GNNExplainer helps in understanding which parts of the graph (edges) and which node features are crucial for the GNN's decision-making process, enhancing transparency and trust in GNN models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
