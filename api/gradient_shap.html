<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Captum · Model Interpretability for PyTorch</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Model Interpretability for PyTorch"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Captum · Model Interpretability for PyTorch"/><meta property="og:type" content="website"/><meta property="og:url" content="https://captum.ai/"/><meta property="og:description" content="Model Interpretability for PyTorch"/><meta property="og:image" content="https://captum.ai/img/captum-icon.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://captum.ai/img/captum.png"/><link rel="shortcut icon" href="/img/captum.ico"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-139570076-2', 'auto');
              ga('send', 'pageview');
            </script><link rel="stylesheet" href="/css/code_block_buttons.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="/js/code_block_buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/js/mathjax.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script><script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script><script>
        document.addEventListener('DOMContentLoaded', function() {
          addBackToTop(
            {"zIndex":100}
          )
        });
        </script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/captum_logo.svg" alt="Captum"/></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/docs/introduction" target="_self">Docs</a></li><li class=""><a href="/tutorials/" target="_self">Tutorials</a></li><li class=""><a href="/api/" target="_self">API Reference</a></li><li class=""><a href="https://github.com/pytorch/captum" target="_self">GitHub</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div>
<script type="text/javascript" id="documentation_options" data-url_root="./"
  src="/js/documentation_options.js"></script>
<script type="text/javascript" src="/js/jquery.js"></script>
<script type="text/javascript" src="/js/underscore.js"></script>
<script type="text/javascript" src="/js/doctools.js"></script>
<script type="text/javascript" src="/js/language_data.js"></script>
<script type="text/javascript" src="/js/searchtools.js"></script>
<div class="sphinx"><div class="document">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body" role="main">
<div class="section" id="module-captum.attr._core.gradient_shap">
<span id="gradientshap"></span><h1>GradientShap<a class="headerlink" href="#module-captum.attr._core.gradient_shap" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="captum.attr._core.gradient_shap.GradientShap">
<em class="property">class </em><code class="descclassname">captum.attr._core.gradient_shap.</code><code class="descname">GradientShap</code><span class="sig-paren">(</span><em>forward_func</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_core/gradient_shap.html#GradientShap"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#captum.attr._core.gradient_shap.GradientShap" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name"/>
<col class="field-body"/>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>forward_func</strong> (<em>function</em>) – The forward function of the model or
any modification of it</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="captum.attr._core.gradient_shap.GradientShap.attribute">
<code class="descname">attribute</code><span class="sig-paren">(</span><em>inputs</em>, <em>baselines</em>, <em>n_samples=5</em>, <em>stdevs=0.0</em>, <em>target=None</em>, <em>additional_forward_args=None</em>, <em>return_convergence_delta=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_core/gradient_shap.html#GradientShap.attribute"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#captum.attr._core.gradient_shap.GradientShap.attribute" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements gradient SHAP based on the implementation from SHAP’s primary
author. For reference, please, view:</p>
<p><a class="reference external" href="https://github.com/slundberg/shap/#deep-learning-example-with-gradientexplainer-tensorflowkeraspytorch-models">https://github.com/slundberg/shap/#deep-learning-example-with-gradientexplainer-tensorflowkeraspytorch-models</a></p>
<p>A Unified Approach to Interpreting Model Predictions
<a class="reference external" href="http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions">http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions</a></p>
<p>GradientShap approximates SHAP values by computing the expectations of
gradients by randomly sampling from the distribution of baselines/references.
It adds white noise to each input sample <cite>n_samples</cite> times, selects a
random baseline from baselines’ distribution and a random point along the
path between the baseline and the input, and computes the gradient of outputs
with respect to those selected random points. The final SHAP values represent
the expected values of gradients * (inputs - baselines).</p>
<p>GradientShap makes an assumption that the input features are independent
and that the explanation model is linear, meaning that the explanations
are modeled through the additive composition of feature effects.
Under those assumptions, SHAP value can be approximated as the expectation
of gradients that are computed for randomly generated <cite>n_samples</cite> input
samples after adding gaussian noise <cite>n_samples</cite> times to each input for
different baselines/references.</p>
<p>In some sense it can be viewed as an approximation of integrated gradients
by computing the expectations of gradients for different baselines.</p>
<p>Current implementation uses Smoothgrad from <cite>NoiseTunnel</cite> in order to
randomly draw samples from the distribution of baselines, add noise to input
samples and compute the expectation (smoothgrad).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"/>
<col class="field-body"/>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inputs</strong> (<em>tensor</em><em> or </em><em>tuple of tensors</em>) – Input for which integrated
gradients are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples, and if multiple input tensors
are provided, the examples must be aligned appropriately.</li>
<li><strong>baselines</strong> (<em>tensor</em><em> or </em><em>tuple of tensors</em><em>, </em><em>optional</em>) – Baselines define
the starting point from which expectation is computed.
If inputs is a single tensor, baselines must also be a
single tensor.
If inputs is a tuple of tensors, baselines must also be
a tuple of tensors, with the same number of tensors as
the inputs. The first dimension in baseline tensors
defines the distribution from which we randomly draw
samples. All other dimensions starting after
the first dimension should match with the inputs’
dimensions after the first dimension. It is recommended that
the number of samples in the baselines’ tensors is larger
than one.
Default: zero tensor for each input tensor</li>
<li><strong>n_samples</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em>) – The number of randomly generated examples
per sample in the input batch. Random examples are
generated by adding gaussian random noise to each sample.
Default: <cite>5</cite> if <cite>n_samples</cite> is not provided.</li>
<li><strong>stdevs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, or </em><em>a tuple of floats optional</em>) – The standard deviation
of gaussian noise with zero mean that is added to each
input in the batch. If <cite>stdevs</cite> is a single float value
then that same value is used for all inputs. If it is
a tuple, then it must have the same length as the inputs
tuple. In this case, each stdev value in the stdevs tuple
corresponds to the input with the same index in the inputs
tuple.
Default: 0.0</li>
<li><strong>target</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>tensor</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a><em>, </em><em>optional</em>) – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><dl class="first docutils">
<dt>a single integer or a tensor containing a single</dt>
<dd>integer, which is applied to all input examples</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>a list of integers or a 1D tensor, with length matching</dt>
<dd>the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</dd>
</dl>
</li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><dl class="first docutils">
<dt>A single tuple, which contains #output_dims - 1</dt>
<dd>elements. This target index is applied to all examples.</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>A list of tuples with length equal to the number of</dt>
<dd>examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</dd>
</dl>
</li>
</ul>
<p>Default: None</p>
</li>
<li><strong>additional_forward_args</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It can contain a tuple of ND tensors or
any arbitrary python type of any shape.
In case of the ND tensor the first dimension of the
tensor must correspond to the batch size. It will be
repeated for each <cite>n_steps</cite> for each randomly generated
input sample.
Note that the gradients are not computed with respect
to these arguments.
Default: None</li>
<li><strong>return_convergence_delta</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Indicates whether to return
convergence delta or not. If <cite>return_convergence_delta</cite>
is set to True convergence delta will be returned in
a tuple following attributions.
Default: False</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><ul class="simple">
<li><dl class="first docutils">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt>
<dd>Attribution score computed based on GradientSHAP with respect
to each input feature. Attributions will always be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>delta</strong> (<em>tensor</em>, returned if return_convergence_delta=True):</dt>
<dd>This is computed using the property that the total
sum of forward_func(inputs) - forward_func(baselines)
must be very close to the total sum of the attributions
based on GradientSHAP.
Delta is calculated for each example in the input after adding
<cite>n_samples</cite> times gaussian noise to each of them. Therefore,
the dimensionality of the deltas tensor is equal to the
<cite>number of examples in the input</cite> * <cite>n_samples</cite>
The deltas are ordered by each input example and <cite>n_samples</cite>
noisy samples generated for it.</dd>
</dl>
</li>
</ul>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># ImageClassifier takes a single input tensor of images Nx3x32x32,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># and returns an Nx10 tensor of class probabilities.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">ImageClassifier</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gradient_shap</span> <span class="o">=</span> <span class="n">GradientShap</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># choosing baselines randomly</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">baselines</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Computes gradient shap for the input</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Attribution size matches input size: 3x3x32x32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attribution</span> <span class="o">=</span> <span class="n">gradient_shap</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">baselines</span><span class="p">,</span>
<span class="go">                                                 target=5)</span>
</pre></div>
</div>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><strong>attributions</strong> or 2-element tuple of <strong>attributions</strong>, <strong>delta</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>
<dl class="method">
<dt id="captum.attr._core.gradient_shap.GradientShap.has_convergence_delta">
<code class="descname">has_convergence_delta</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_core/gradient_shap.html#GradientShap.has_convergence_delta"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#captum.attr._core.gradient_shap.GradientShap.has_convergence_delta" title="Permalink to this definition">¶</a></dt>
<dd><p>This method informs the user whether the attribution algorithm provides
a convergence delta (aka an approximation error) or not. Convergence
delta may serve as a proxy of correctness of attribution algorithm’s
approximation. If deriving attribution class provides a
<cite>compute_convergence_delta</cite> method, it should
override both <cite>compute_convergence_delta</cite> and <cite>has_convergence_delta</cite> methods.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"/>
<col class="field-body"/>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Returns whether the attribution algorithm
provides a convergence delta (aka approximation error) or not.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)">bool</a></td>
</tr>
</tbody>
</table>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="captum.attr._core.gradient_shap.InputBaselineXGradient">
<em class="property">class </em><code class="descclassname">captum.attr._core.gradient_shap.</code><code class="descname">InputBaselineXGradient</code><span class="sig-paren">(</span><em>forward_func</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_core/gradient_shap.html#InputBaselineXGradient"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#captum.attr._core.gradient_shap.InputBaselineXGradient" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name"/>
<col class="field-body"/>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>forward_func</strong> (<em>function</em>) – The forward function of the model or
any modification of it</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="captum.attr._core.gradient_shap.InputBaselineXGradient.attribute">
<code class="descname">attribute</code><span class="sig-paren">(</span><em>inputs</em>, <em>baselines=None</em>, <em>target=None</em>, <em>additional_forward_args=None</em>, <em>return_convergence_delta=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_core/gradient_shap.html#InputBaselineXGradient.attribute"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#captum.attr._core.gradient_shap.InputBaselineXGradient.attribute" title="Permalink to this definition">¶</a></dt>
<dd><p>This method computes and returns the attribution values for each input tensor.
Deriving classes are responsible for implementing its logic accordingly.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"/>
<col class="field-body"/>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inputs</strong> (<em>tensor</em><em> or </em><em>tuple of tensors</em>) – Input for which attribution
is computed. It can be provided as a single tensor or
a tuple of multiple tensors. If multiple input tensors
are provided, the batch sizes must be aligned accross all
tensors.</li>
<li><strong>**kwargs</strong> (<em>Any</em><em>, </em><em>optional</em>) – Arbitrary keyword arguments used by specific
attribution algorithms that extend this class.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><ul class="simple">
<li><dl class="first docutils">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt>
<dd>Attribution values for each
input tensor. The <cite>attributions</cite> have the same shape and
dimensionality as the inputs.
If a single tensor is provided as inputs, a single tensor
is returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</dd>
</dl>
</li>
</ul>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><em>tensor</em> or tuple of <em>tensors</em> of <strong>attributions</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>
<dl class="method">
<dt id="captum.attr._core.gradient_shap.InputBaselineXGradient.has_convergence_delta">
<code class="descname">has_convergence_delta</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_core/gradient_shap.html#InputBaselineXGradient.has_convergence_delta"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#captum.attr._core.gradient_shap.InputBaselineXGradient.has_convergence_delta" title="Permalink to this definition">¶</a></dt>
<dd><p>This method informs the user whether the attribution algorithm provides
a convergence delta (aka an approximation error) or not. Convergence
delta may serve as a proxy of correctness of attribution algorithm’s
approximation. If deriving attribution class provides a
<cite>compute_convergence_delta</cite> method, it should
override both <cite>compute_convergence_delta</cite> and <cite>has_convergence_delta</cite> methods.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"/>
<col class="field-body"/>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Returns whether the attribution algorithm
provides a convergence delta (aka approximation error) or not.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)">bool</a></td>
</tr>
</tbody>
</table>
</dd></dl>
</dd></dl>
</div>
</div>
</div>
</div>
<div aria-label="main navigation" class="sphinxsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">Captum</a></h1>
<h3>Navigation</h3>
<p class="caption"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="saliency.html">Saliency</a></li>
<li class="toctree-l1"><a class="reference internal" href="deep_lift.html">DeepLift</a></li>
<li class="toctree-l1"><a class="reference internal" href="deep_lift_shap.html">DeepLiftShap</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">GradientShap</a></li>
<li class="toctree-l1"><a class="reference internal" href="input_x_gradient.html">InputXGradient</a></li>
<li class="toctree-l1"><a class="reference internal" href="integrated_gradients.html">IntegratedGradients</a></li>
<li class="toctree-l1"><a class="reference internal" href="noise_tunnel.html">NoiseTunnel</a></li>
<li class="toctree-l1"><a class="reference internal" href="utilities.html">Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="neuron.html">neuron</a></li>
<li class="toctree-l1"><a class="reference internal" href="layer.html">layer</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
<li><a href="index.html">Documentation overview</a><ul>
<li>Previous: <a href="deep_lift_shap.html" title="previous chapter">DeepLiftShap</a></li>
<li>Next: <a href="input_x_gradient.html" title="next chapter">InputXGradient</a></li>
</ul></li>
</ul>
</div>
<div id="searchbox" role="search" style="display: none">
<h3>Quick search</h3>
<div class="searchformwrapper">
<form action="search.html" class="search" method="get">
<input name="q" type="text"/>
<input type="submit" value="Go"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
</div>
</div>
<div class="clearer"></div>
</div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><div class="footerSection"><h5>Docs</h5><a href="/docs/introduction">Introduction</a><a href="/docs/getting_started">Getting Started</a><a href="/tutorials/">Tutorials</a><a href="/api/">API Reference</a></div><div class="footerSection"><h5>Social</h5><div class="social"><a class="github-button" href="https://github.com/pytorch/captum" data-count-href="https://github.com/pytorch/captum/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star Captum on GitHub">captum</a></div></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a><section class="copyright"> Copyright © 2019 Facebook Inc.</section></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '207c27d819f967749142d8611de7cb19',
                indexName: 'captum',
                inputSelector: '#search_input_react'
              });
            </script></body></html>